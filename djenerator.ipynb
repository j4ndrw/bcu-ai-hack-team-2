{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "djent_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZbOnT7fn6EyVfkWsnQuQQ8MYtK6ybrBx",
      "authorship_tag": "ABX9TyNkyKi187LsaxHk9V/9c46i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j4ndrw/bcu-ai-hack-team-2/blob/master/djenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLw283NNzTWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ./models ./drive/My\\ Drive/Djenerator"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7_d23wDkmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "import torchvision\n",
        "\n",
        "from tensorflow import summary\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import librosa\n",
        "import os\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qasa4mf4bSGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_rate = 44100\n",
        "seconds = 30\n",
        "\n",
        "placeholder_dataset = []\n",
        "\n",
        "for wav_file in os.listdir(\"/content/drive/My Drive/Djenerator/data\"):\n",
        "  if wav_file.endswith(\".wav\"):\n",
        "    y, sample_rate = librosa.load(path = f\"/content/drive/My Drive/Djenerator/data/{wav_file}\", sr = sample_rate)\n",
        "    y = y[y != 0]\n",
        "    duration = y.shape[0] // sample_rate\n",
        "    for i in range(0, duration, seconds):\n",
        "      placeholder_dataset.append(y[i * sample_rate : (i + seconds) * sample_rate])\n",
        "\n",
        "num_subsamples = len(placeholder_dataset)\n",
        "del placeholder_dataset\n",
        "\n",
        "dataset = np.empty((num_subsamples, sample_rate * seconds), dtype = np.float32)\n",
        "\n",
        "for wav_file in os.listdir(\"/content/drive/My Drive/Djenerator/data/\"):\n",
        "  if wav_file.endswith(\".wav\"):\n",
        "    y, sample_rate = librosa.load(path = f\"/content/drive/My Drive/Djenerator/data/{wav_file}\", sr = sample_rate)\n",
        "    y = y[y != 0]\n",
        "    duration = y.shape[0] // sample_rate\n",
        "    for i in range(0, duration, seconds):\n",
        "      np.append(dataset, y[i * sample_rate : (i + seconds) * sample_rate])\n",
        "      # dataset.append(y[i * sample_rate : (i + 1) * sample_rate])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbB0pJTudqYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "a64f92b9-8851-4c35-c310-e3db06e4569f"
      },
      "source": [
        "dataset.shape, np.max(dataset[2]), np.min(dataset[2]), dataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50, 1323000),\n",
              " 0.5631256,\n",
              " -0.5678406,\n",
              " array([[ 1.5258789e-05, -1.5258789e-05,  3.0517578e-05, ...,\n",
              "         -2.2033691e-02, -2.1316528e-02, -4.6112061e-02],\n",
              "        [-5.3390503e-02, -5.1086426e-02, -2.0339966e-02, ...,\n",
              "          7.4005127e-03,  1.6098022e-02,  2.4765015e-02],\n",
              "        [ 3.1936646e-02,  3.7017822e-02,  4.0191650e-02, ...,\n",
              "         -4.8599243e-02, -3.6102295e-02, -3.3523560e-02],\n",
              "        ...,\n",
              "        [ 2.3559570e-01,  3.6682129e-02,  2.0269775e-01, ...,\n",
              "          8.3251953e-02,  1.7260742e-01,  5.6945801e-02],\n",
              "        [ 1.8127441e-01,  2.0202637e-02,  1.6107178e-01, ...,\n",
              "          8.7982178e-02, -7.5408936e-02,  9.0087891e-02],\n",
              "        [-8.8562012e-02,  8.0749512e-02, -7.7148438e-02, ...,\n",
              "         -1.7547607e-01, -5.8441162e-02, -2.9122925e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzEBIq3MaPj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_features, output_features):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "\n",
        "    self.l_in = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = self.input_features,\n",
        "            out_features = 64\n",
        "        ),\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2\n",
        "        ),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.batch_norm = nn.BatchNorm1d(64, eps = 1e-03, momentum = 0.5)\n",
        "\n",
        "\n",
        "    self.h1 = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 64,\n",
        "            out_features = 32\n",
        "        ),\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2\n",
        "        ),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.l_out = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 32,\n",
        "            out_features = output_features\n",
        "        ),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.l_in(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = self.h1(x)\n",
        "    x = self.l_out(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_features, output_features):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "\n",
        "    self.l_in = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = self.input_features,\n",
        "            out_features = 32\n",
        "        ),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.batch_norm1 = nn.BatchNorm1d(32, eps = 1e-03, momentum = 0.2)\n",
        "\n",
        "    self.h1 = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 32,\n",
        "            out_features = 64\n",
        "        ),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.batch_norm2 = nn.BatchNorm1d(64, eps = 1e-04, momentum = 0.2)\n",
        "\n",
        "    self.h2 = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 64,\n",
        "            out_features = 128\n",
        "        ),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.l_out = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 128,\n",
        "            out_features = output_features\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def nn_sin(self, x):\n",
        "    return x * torch.sin(x)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.l_in(x)\n",
        "    x = self.batch_norm1(x)\n",
        "    x = self.h1(x)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = self.h2(x)\n",
        "    x = self.nn_sin(self.l_out(x))\n",
        "    return x\n",
        "\n",
        "class GAN():\n",
        "  def __init__(self, dataset, batch_size, shuffle, song_features, noise_vector_latent_dim, num_output_samples):\n",
        "    \n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "\n",
        "    self.song_features = song_features\n",
        "\n",
        "    self.noise_vector_latent_dim = noise_vector_latent_dim\n",
        "    self.num_output_samples = num_output_samples\n",
        "\n",
        "    self.data_loader = torch.utils.data.DataLoader(self.dataset, batch_size = self.batch_size, shuffle = self.shuffle)\n",
        "    self.num_batches = len(self.data_loader)\n",
        "\n",
        "    self.discriminator = Discriminator(input_features = song_features, output_features = 1)\n",
        "    self.generator = Generator(input_features = noise_vector_latent_dim, output_features = song_features)\n",
        "\n",
        "    self.d_opt = optim.Adam(self.discriminator.parameters(), lr = 0.0002, betas=(0.5, 0.999))\n",
        "    self.g_opt = optim.Adam(self.generator.parameters(), lr = 0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    self.samples = []\n",
        "\n",
        "    self.BCELoss = nn.BCELoss()\n",
        "\n",
        "  def train_disc(self, opt, real, fake, step):\n",
        "    opt.zero_grad()\n",
        "\n",
        "    self.pred_real = self.discriminator(real)\n",
        "\n",
        "    smoothed_labels = np.zeros((real.size(0), 1), dtype = np.float32)\n",
        "    for i in range(len(smoothed_labels)):\n",
        "      smoothed_labels[i] = 0.9\n",
        "    self.error_real = self.BCELoss(self.pred_real, torch.from_numpy(smoothed_labels))\n",
        "    self.error_real.backward()\n",
        "\n",
        "    self.pred_fake = self.discriminator(fake)\n",
        "    self.error_fake = self.BCELoss(self.pred_fake, torch.zeros(real.size(0), 1))\n",
        "    self.error_fake.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    return self.error_real, self.error_fake, self.error_real + self.error_fake\n",
        "\n",
        "  def train_gen(self, opt, fake, step):\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    self.pred_fake = self.discriminator(fake)\n",
        "    self.error_fake = self.BCELoss(self.pred_fake, torch.ones(fake.size(0), 1))\n",
        "    self.error_fake.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    return self.error_fake\n",
        "\n",
        "  def noise(self,  N):\n",
        "    return torch.randn((N, self.noise_vector_latent_dim))\n",
        "\n",
        "  def challenge_discriminator(self, real: torch.Tensor, noise_size: int, rate: float):\n",
        "    chance = np.random.randint(0, 100)\n",
        "    if chance <= int(rate * 100):\n",
        "      return real * torch.randn(noise_size)\n",
        "    else:\n",
        "      return real\n",
        "\n",
        "  def vec2wave(self, vec, size):\n",
        "    return vec.view(vec.size(0), size)\n",
        "\n",
        "  def train(self, epochs, start_epoch, eval_every):\n",
        "    step = 0\n",
        "\n",
        "    test_noise = self.noise(self.num_output_samples)\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "      for n_batch, real in enumerate(self.data_loader):\n",
        "        N = real.size(0)\n",
        "        step += 1\n",
        "\n",
        "        real = real.view(N, self.song_features)\n",
        "\n",
        "        noisify_real_rate = 0.01\n",
        "        if step % 50 == 0:\n",
        "          noisify_real_rate = 0.1\n",
        "        if step % 100 == 0:\n",
        "          noisify_real_rate = 0.2\n",
        "        if step % 1000 == 0:\n",
        "          noisify_real_rate = 0.3\n",
        "\n",
        "        real = self.challenge_discriminator(real = real, noise_size = self.song_features, rate = noisify_real_rate)\n",
        "\n",
        "        fake = self.generator(self.noise(N)).detach()\n",
        "\n",
        "        d_error_real, d_error_fake, d_error_total = self.train_disc(self.d_opt, real, fake, step)\n",
        "\n",
        "        fake = self.generator(self.noise(N))\n",
        "        g_error = self.train_gen(self.g_opt, fake, step)\n",
        "        \n",
        "        sys.stdout.write(\"\\r\" + f\"d_error_real = {d_error_real:.2f} -> d_error_fake = {d_error_fake:.2f} -> d_error_total = {d_error_total:.2f} -> g_error = {g_error:.2f} -> epoch = {epoch + 1} -> batch = {n_batch + 1} / {self.num_batches}\")\n",
        "\n",
        "        if (epoch + 1) % eval_every == 0 and n_batch == 0:\n",
        "          sys.stdout.write(\"\\r\" + \"Updating list of samples | Saving Discriminator model | Saving Generator model\")\n",
        "\n",
        "          torch.save(\n",
        "          {\n",
        "              \"epoch\" : epoch,\n",
        "              \"model_state_dict\" : self.discriminator.state_dict(),\n",
        "              \"optimizer_state_dict\" : self.d_opt.state_dict(),\n",
        "              \"losses\" : [d_error_real, d_error_fake, d_error_total]\n",
        "          }, \n",
        "          \"/content/drive/My Drive/Djenerator/models/discriminator.pth\")\n",
        "\n",
        "          torch.save(\n",
        "          {\n",
        "              \"epoch\" : epoch,\n",
        "              \"model_state_dict\" : self.generator.state_dict(),\n",
        "              \"optimizer_state_dict\" : self.g_opt.state_dict(),\n",
        "              \"losses\" : [g_error]\n",
        "          }, \n",
        "          \"/content/drive/My Drive/Djenerator/models/generator.pth\")    \n",
        "\n",
        "          self.samples.append(self.vec2wave(self.generator(test_noise), self.song_features).data)\n",
        "          np.save(f\"./content/drive/My Drive/Djenerator/djenerated_samples_raw/{self.num_output_samples}_samples_at_epoch_{epoch + 1}.npy\", self.samples[-1].numpy())  \n",
        "        \n",
        "  def resume_gan_training(self, epochs, eval_every):\n",
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator and generator models\")\n",
        "    discriminator_checkpoint = torch.load(\"/content/drive/My Drive/Djenerator/models/discriminator.pth\")\n",
        "    generator_checkpoint = torch.load(\"/content/drive/My Drive/Djenerator/models/generator.pth\")\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Getting most recent epoch\")\n",
        "    start_epoch = discriminator_checkpoint['epoch']\n",
        "    \n",
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator optimizers\")\n",
        "    self.d_opt = discriminator_checkpoint['optimizer_state_dict']\n",
        "    self.discriminator.load_state_dict(discriminator_checkpoint['model_state_dict'])\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator losses\")\n",
        "    d_error_real, d_error_fake, d_error_total = discriminator_checkpoint['losses'][0], discriminator_checkpoint['losses'][1], discriminator_checkpoint['losses'][2]\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Loading generator optimizers\")\n",
        "    self.g_opt = generator_checkpoint['optimizer_state_dict']\n",
        "    self.generator.load_state_dict(generator_checkpoint['model_state_dict'])\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Loading generator loss\")\n",
        "    g_error = generator_checkpoint['losses'][0]\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Fetching batch norm gradients\")\n",
        "    self.discriminator.eval()\n",
        "    self.generator.eval()\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Setting models in train mode\")\n",
        "    self.discriminator.train()\n",
        "    self.generator.train()\n",
        "\n",
        "    self.train_gan(epochs = epochs, start_epoch = epoch, eval_every = eval_every)\n",
        "  \n",
        "  def get_all_generated_samples(self):\n",
        "    return self.samples"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWYhR4aj5A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = GAN(\n",
        "  dataset = dataset,\n",
        "  batch_size = 10,\n",
        "  shuffle = True,\n",
        "  song_features = sample_rate * seconds, \n",
        "  noise_vector_latent_dim = 100,\n",
        "  num_output_samples = 10\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRvuTsoiT6-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21c63ebb-8a5b-4c85-a4ce-5ea046e8aa9d"
      },
      "source": [
        "gan.train(start_epoch = 0, epochs = 100000, eval_every = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_error_real = 0.70 -> d_error_fake = 0.29 -> d_error_total = 0.99 -> g_error = 2.01 -> epoch = 244 -> batch = 3 / 5"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byYEmG_J1iuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "756d8360-a7ee-42a3-aa16-f9be854b7223"
      },
      "source": [
        "gan.resume_gan_training(epochs = 100000, eval_every = 300)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting models in train mode"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-aa3b43e9d690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_gan_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-f2d3a7bb91f0>\u001b[0m in \u001b[0;36mresume_gan_training\u001b[0;34m(self, epochs, eval_every)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_all_generated_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GAN' object has no attribute 'train_gan'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbxhEyL7IrSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = gan.get_all_generated_samples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIHtWh8sIvXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(f\"/content/drive/My Drive/Djenerator/djenerated_samples_raw/10_samples_at_epoch_10.npy\", samples[-1].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}